{"cells":[{"cell_type":"markdown","metadata":{"id":"wK4s_BnWfCUw"},"source":["**Network architecture**\n","- [ ] Number of hidden layers (network depth) \n","- [ ] Number of neurons in each layer (layer width) \n","- [ ] Activation type \n","\n","**Learning and optimization**\n","- [ ] Learning rate and decay schedule\n","- [ ] Mini-batch size\n","- [ ] Optimization algorithms\n","- [ ] Number of training iterations or epochs (and early stopping criteria)\n","\n","**Regularization techniques to avoid overfitting** \n","- [ ] L2 regularization\n","- [ ] Dropout layers\n","- [ ] Data augmentation\n","- [ ] Batch normalization\n","- [ ] Transfer learning\n"]},{"cell_type":"markdown","metadata":{"id":"exf7DUxpKI2K"},"source":["# 變數\n","- [ ] load_weights : val_loss: 0.4617 - val_accuracy: 0.8414\n","- [ ] target size : 450*450\n","- [ ] learnging rate: 1e-6\n","- [ ] batch size : 10\n","- [ ] class weight\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4zTs2F2cyCDl"},"source":["# 結果\n","- [ ] val_loss: 0.4693 - val_accuracy: 0.8495\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIH3DOIAqliU"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import os\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing import image\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3093,"status":"ok","timestamp":1641252305342,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"},"user_tz":-480},"id":"cV5h_R6a_G-g","outputId":"c21d20b1-e433-4952-f053-95a1255515fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMvkk9k6khPE"},"outputs":[],"source":["# select 'add to my drive' on the shared folder\n","\n","\n","root_path = 'gdrive/MyDrive/final_project'\n","train_dir='gdrive/MyDrive/final_project/train_and_unlabeled/all' #train jpg save place \n","train_df = pd.read_csv(f'{root_path}/train_and_unlabeled/600_unlabel_4.csv') # includes unlabeled data\n","\n","\n","#train_df=train_df.append(train_df.loc[1,:],ignore_index=True)\n","train_df['Type'] = train_df['Type'].astype('str') #如果class_mode = 'sparse'要是string要是string"]},{"cell_type":"markdown","metadata":{"id":"G3AvFsVxKM1O"},"source":["## InceptionResNetV2"]},{"cell_type":"code","source":["# Data agumentation and pre-processing using tensorflow\n","train_gen = ImageDataGenerator(   \n","                rotation_range = 15,\n","                zoom_range = 0.15,\n","                width_shift_range=0.1,\n","                height_shift_range=0.1,\n","                shear_range=0.1,\n","                fill_mode='nearest',\n","                rescale=1./255.,\n","                horizontal_flip = True,\n","                validation_split=0.2005 # training: 80% data, validation: 20% data\n","                 )\n","\n","valid_gen = ImageDataGenerator(   \n","                # rotation_range = 40,\n","                # zoom_range = 0.15,\n","                # width_shift_range=0.2,\n","                # height_shift_range=0.2,\n","                # shear_range=0.2,\n","                # fill_mode='nearest',\n","                rescale=1./255.,\n","                # horizontal_flip = True,\n","                validation_split=0.2005 # training: 80% data, validation: 20% data\n","                 )\n","  \n","train_generator = train_gen.flow_from_dataframe(\n","    train_df, # dataframe\n","    directory = train_dir, # images data path / folder in which images are there\n","    x_col = 'Name',\n","    y_col = 'Type',\n","    subset=\"training\",\n","    color_mode=\"rgb\",\n","    target_size = (600,600), # image height , image width\n","    class_mode=\"categorical\",\n","    batch_size=10,\n","    shuffle=True,\n","    seed=42,\n",")\n","  \n","  \n","validation_generator = valid_gen.flow_from_dataframe(\n","    train_df, # dataframe\n","    directory = train_dir, # images data path / folder in which images are there\n","    x_col = 'Name',\n","    y_col = 'Type',\n","    subset=\"validation\",\n","    color_mode=\"rgb\",\n","    target_size = (600,600), # image height , image width\n","    class_mode=\"categorical\",\n","    batch_size=10,\n","    shuffle=True,\n","    seed=42,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dx2SLqEnMSKJ","executionInfo":{"status":"ok","timestamp":1641252322121,"user_tz":-480,"elapsed":16784,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"7a811482-2b34-4cf6-89d8-6f592e3564fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 11332 validated image filenames belonging to 4 classes.\n","Found 2841 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPvuVk2-XLGM"},"outputs":[],"source":["# train_labels=np.array([])\n","# for i in tqdm(range(train_generator.n//train_generator.batch_size)):\n","#   feat = train_generator[i][-1]\n","#   labels = np.argmax(feat, axis=1)\n","#   train_labels = np.append(train_labels,labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4WzafAkaZN6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641208995646,"user_tz":-480,"elapsed":9,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"3e15efb3-874a-45b0-bef3-e3fc0810c4f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'0.0': 0.9391068115557911, '1.0': 0.9205637828007275, '2.0': 1.1609600262123199, '3.0': 1.0126464704201201}\n"]}],"source":["from sklearn.utils import class_weight\n","train_labels = train_df['Type']\n","ClassWeights = dict(zip(np.unique(train_labels),\n","                        class_weight.compute_class_weight('balanced',\n","                                                classes=np.unique(train_labels),y=train_labels)))\n","print(ClassWeights) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"raVHrssK8HvF"},"outputs":[],"source":["ClassWeights ={0.0: 0.9391068115557911, 1.0: 0.9205637828007275, 2.0: 1.1609600262123199, 3.0: 1.0126464704201201}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnPkv-IBC0xJ"},"outputs":[],"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import CSVLogger\n","\n","# load the InceptionResNetV2 architecture with imagenet weights as base\n","base_model = tf.keras.applications.InceptionResNetV2(\n","                     include_top=False,\n","                     weights='imagenet',\n","                     input_shape=(600,600,3)\n","                     )\n","  \n","base_model.trainable=False\n","# For freezing the layer we make use of layer.trainable = False\n","# means that its internal state will not change during training.\n","# model's trainable weights will not be updated during fit(),\n","# and also its state updates will not run.\n","  \n","model = tf.keras.Sequential([ \n","        base_model,   \n","        tf.keras.layers.BatchNormalization(renorm=True),\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(256, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(4, activation='softmax')\n","    ])\n","\n","opt = optimizers.Adam(learning_rate = 0.0001)\n","\n","model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n","# categorical cross entropy is taken since its used as a loss function for \n","# multi-class classification problems where there are two or more output labels.\n","# using Adam optimizer for better performance\n","# other optimizers such as sgd can also be used depending upon the model\n","\n","mc = ModelCheckpoint(os.path.join('gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5'),\n","                     monitor='val_accuracy',\n","                     verbose=1,\n","                     save_best_only=True,\n","                     save_weights_only=True,\n","                     mode='max')\n","\n","early = tf.keras.callbacks.EarlyStopping(  #monitor = 'val_accuracy',\n","                       #mode = 'max',\n","                       patience=10,\n","                       min_delta=0.0001,\n","                       restore_best_weights=True)\n","\n","log = CSVLogger('gdrive/MyDrive/final_project/code/soil/600_unlabel_4.csv')\n","\n","batch_size=10\n","STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqAs0aulBRNn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641237975792,"user_tz":-480,"elapsed":28906082,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"0f88b1c8-63c4-4a90-9929-9508427f91bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.7643 - accuracy: 0.7019\n","Epoch 00001: val_accuracy improved from -inf to 0.81444, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 5825s 5s/step - loss: 0.7643 - accuracy: 0.7019 - val_loss: 0.5211 - val_accuracy: 0.8144\n","Epoch 2/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8213\n","Epoch 00002: val_accuracy improved from 0.81444 to 0.82711, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1057s 933ms/step - loss: 0.4962 - accuracy: 0.8213 - val_loss: 0.5033 - val_accuracy: 0.8271\n","Epoch 3/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8418\n","Epoch 00003: val_accuracy did not improve from 0.82711\n","1133/1133 [==============================] - 1064s 939ms/step - loss: 0.4516 - accuracy: 0.8418 - val_loss: 0.4938 - val_accuracy: 0.8264\n","Epoch 4/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8493\n","Epoch 00004: val_accuracy improved from 0.82711 to 0.82746, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1078s 952ms/step - loss: 0.4246 - accuracy: 0.8493 - val_loss: 0.4871 - val_accuracy: 0.8275\n","Epoch 5/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.8577\n","Epoch 00005: val_accuracy improved from 0.82746 to 0.82958, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1072s 946ms/step - loss: 0.4022 - accuracy: 0.8577 - val_loss: 0.4762 - val_accuracy: 0.8296\n","Epoch 6/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.8592\n","Epoch 00006: val_accuracy improved from 0.82958 to 0.83380, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1056s 932ms/step - loss: 0.3928 - accuracy: 0.8592 - val_loss: 0.4713 - val_accuracy: 0.8338\n","Epoch 7/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8639\n","Epoch 00007: val_accuracy improved from 0.83380 to 0.83451, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1062s 937ms/step - loss: 0.3756 - accuracy: 0.8639 - val_loss: 0.4763 - val_accuracy: 0.8345\n","Epoch 8/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8735\n","Epoch 00008: val_accuracy did not improve from 0.83451\n","1133/1133 [==============================] - 1063s 938ms/step - loss: 0.3577 - accuracy: 0.8735 - val_loss: 0.4750 - val_accuracy: 0.8342\n","Epoch 9/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.8702\n","Epoch 00009: val_accuracy improved from 0.83451 to 0.83908, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1102s 972ms/step - loss: 0.3611 - accuracy: 0.8702 - val_loss: 0.4710 - val_accuracy: 0.8391\n","Epoch 10/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8749\n","Epoch 00010: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1081s 954ms/step - loss: 0.3439 - accuracy: 0.8749 - val_loss: 0.4698 - val_accuracy: 0.8349\n","Epoch 11/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8769\n","Epoch 00011: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1114s 983ms/step - loss: 0.3477 - accuracy: 0.8769 - val_loss: 0.4712 - val_accuracy: 0.8349\n","Epoch 12/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8825\n","Epoch 00012: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1100s 970ms/step - loss: 0.3366 - accuracy: 0.8825 - val_loss: 0.4677 - val_accuracy: 0.8359\n","Epoch 13/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8818\n","Epoch 00013: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1068s 942ms/step - loss: 0.3257 - accuracy: 0.8818 - val_loss: 0.4732 - val_accuracy: 0.8356\n","Epoch 14/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.8837\n","Epoch 00014: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1104s 974ms/step - loss: 0.3183 - accuracy: 0.8837 - val_loss: 0.4696 - val_accuracy: 0.8370\n","Epoch 15/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8892\n","Epoch 00015: val_accuracy did not improve from 0.83908\n","1133/1133 [==============================] - 1063s 938ms/step - loss: 0.3144 - accuracy: 0.8892 - val_loss: 0.4766 - val_accuracy: 0.8342\n","Epoch 16/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8920\n","Epoch 00016: val_accuracy improved from 0.83908 to 0.83944, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1067s 941ms/step - loss: 0.3046 - accuracy: 0.8920 - val_loss: 0.4702 - val_accuracy: 0.8394\n","Epoch 17/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.8926\n","Epoch 00017: val_accuracy improved from 0.83944 to 0.83979, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1106s 976ms/step - loss: 0.3019 - accuracy: 0.8926 - val_loss: 0.4704 - val_accuracy: 0.8398\n","Epoch 18/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8941\n","Epoch 00018: val_accuracy did not improve from 0.83979\n","1133/1133 [==============================] - 1064s 939ms/step - loss: 0.2874 - accuracy: 0.8941 - val_loss: 0.4733 - val_accuracy: 0.8370\n","Epoch 19/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.8944\n","Epoch 00019: val_accuracy improved from 0.83979 to 0.84190, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1088s 960ms/step - loss: 0.2861 - accuracy: 0.8944 - val_loss: 0.4737 - val_accuracy: 0.8419\n","Epoch 20/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.8919\n","Epoch 00020: val_accuracy did not improve from 0.84190\n","1133/1133 [==============================] - 1084s 957ms/step - loss: 0.2901 - accuracy: 0.8919 - val_loss: 0.4713 - val_accuracy: 0.8387\n","Epoch 21/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.8998\n","Epoch 00021: val_accuracy improved from 0.84190 to 0.84401, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5\n","1133/1133 [==============================] - 1064s 939ms/step - loss: 0.2840 - accuracy: 0.8998 - val_loss: 0.4723 - val_accuracy: 0.8440\n","Epoch 22/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9010\n","Epoch 00022: val_accuracy did not improve from 0.84401\n","1133/1133 [==============================] - 1097s 968ms/step - loss: 0.2749 - accuracy: 0.9010 - val_loss: 0.4817 - val_accuracy: 0.8373\n"]}],"source":["# fit model\n","history = model.fit(\n","                    train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=validation_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    class_weight = ClassWeights,\n","                    epochs = 50,\n","                    callbacks=[early, mc, log]\n","                    )\n","#model.load_weights('gdrive/MyDrive/final_project/code/resnetV2_augment_lr_600_3_bal_mod.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17404,"status":"ok","timestamp":1641252348929,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"},"user_tz":-480},"id":"xXsm1aK21Ocg","outputId":"29a63b02-0fcb-4a3b-dd39-4edaa7d7723d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 11332 validated image filenames belonging to 4 classes.\n","Found 2841 validated image filenames belonging to 4 classes.\n"]}],"source":["# Data agumentation and pre-processing using tensorflow\n","gen = ImageDataGenerator(\n","                  rescale=1./255.,\n","                  horizontal_flip = True,\n","                  validation_split=0.2005 # training: 80% data, validation: 20% data\n","                 )\n","  \n","train_generator = gen.flow_from_dataframe(\n","    train_df, # dataframe\n","    directory = train_dir, # images data path / folder in which images are there\n","    x_col = 'Name',\n","    y_col = 'Type',\n","    subset=\"training\",\n","    color_mode=\"rgb\",\n","    target_size = (600,600), # image height , image width\n","    class_mode=\"categorical\",\n","    batch_size=10,\n","    shuffle=True,\n","    seed=42,\n",")\n","  \n","  \n","validation_generator = gen.flow_from_dataframe(\n","    train_df, # dataframe\n","    directory = train_dir, # images data path / folder in which images are there\n","    x_col = 'Name',\n","    y_col = 'Type',\n","    subset=\"validation\",\n","    color_mode=\"rgb\",\n","    target_size = (600,600), # image height , image width\n","    class_mode=\"categorical\",\n","    batch_size=10,\n","    shuffle=True,\n","    seed=42,\n",")"]},{"cell_type":"code","source":["# from tensorflow.keras import models\n","# from tensorflow.keras import layers\n","# from tensorflow.keras import optimizers\n","# from tensorflow.keras.callbacks import ModelCheckpoint\n","# from tensorflow.keras.callbacks import EarlyStopping\n","# from tensorflow.keras.callbacks import CSVLogger\n","\n","# # load the InceptionResNetV2 architecture with imagenet weights as base\n","# base_model = tf.keras.applications.InceptionResNetV2(\n","#                      include_top=False,\n","#                      weights='imagenet',\n","#                      input_shape=(600,600,3)\n","#                      )\n","  \n","# base_model.trainable=False\n","# # For freezing the layer we make use of layer.trainable = False\n","# # means that its internal state will not change during training.\n","# # model's trainable weights will not be updated during fit(),\n","# # and also its state updates will not run.\n","  \n","# model = tf.keras.Sequential([ \n","#         base_model,   \n","#         tf.keras.layers.BatchNormalization(renorm=True),\n","#         tf.keras.layers.GlobalAveragePooling2D(),\n","#         tf.keras.layers.Dense(128, activation='relu'),\n","#         tf.keras.layers.Dropout(0.5),\n","#         tf.keras.layers.Dense(256, activation='relu'),\n","#         tf.keras.layers.Dropout(0.5),\n","#         tf.keras.layers.Dense(4, activation='softmax')\n","#     ])\n","\n","# opt = optimizers.Adam(learning_rate = 0.0001)\n","\n","# model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n","# categorical cross entropy is taken since its used as a loss function for \n","# multi-class classification problems where there are two or more output labels.\n","# using Adam optimizer for better performance\n","# other optimizers such as sgd can also be used depending upon the model\n","\n","mc = ModelCheckpoint(os.path.join('gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5'),\n","                     monitor='val_accuracy',\n","                     verbose=1,\n","                     save_best_only=True,\n","                     save_weights_only=True,\n","                     mode='max')\n","\n","early = tf.keras.callbacks.EarlyStopping(#monitor = 'val_accuracy',\n","                       #mode = 'max',\n","                       patience=6,\n","                       min_delta=0.0001,\n","                       restore_best_weights=True)\n","\n","log = CSVLogger('gdrive/MyDrive/final_project/code/soil/600_unlabel_mod_4.csv')\n","\n","batch_size=10\n","STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n","  \n"],"metadata":{"id":"44NuEqQ7Nqj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULdJIoThCAyY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"746feafc-19f5-484b-a206-01909982861e","executionInfo":{"status":"ok","timestamp":1641266032179,"user_tz":-480,"elapsed":13642057,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_resnet_v2 (Functi  (None, 17, 17, 1536)     54336736  \n"," onal)                                                           \n","                                                                 \n"," batch_normalization_203 (Ba  (None, 17, 17, 1536)     10752     \n"," tchNormalization)                                               \n","                                                                 \n"," global_average_pooling2d (G  (None, 1536)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 128)               196736    \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               33024     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 4)                 1028      \n","                                                                 \n","=================================================================\n","Total params: 54,578,276\n","Trainable params: 54,510,052\n","Non-trainable params: 68,224\n","_________________________________________________________________\n","Epoch 1/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.9171\n","Epoch 00001: val_accuracy improved from -inf to 0.83732, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5\n","1133/1133 [==============================] - 7176s 6s/step - loss: 0.2386 - accuracy: 0.9171 - val_loss: 0.5097 - val_accuracy: 0.8373\n","Epoch 2/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.9196\n","Epoch 00002: val_accuracy improved from 0.83732 to 0.84648, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5\n","1133/1133 [==============================] - 917s 809ms/step - loss: 0.2372 - accuracy: 0.9196 - val_loss: 0.4954 - val_accuracy: 0.8465\n","Epoch 3/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9347\n","Epoch 00003: val_accuracy did not improve from 0.84648\n","1133/1133 [==============================] - 911s 804ms/step - loss: 0.1907 - accuracy: 0.9347 - val_loss: 0.5305 - val_accuracy: 0.8440\n","Epoch 4/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9469\n","Epoch 00004: val_accuracy did not improve from 0.84648\n","1133/1133 [==============================] - 910s 803ms/step - loss: 0.1457 - accuracy: 0.9469 - val_loss: 0.5719 - val_accuracy: 0.8405\n","Epoch 5/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9603\n","Epoch 00005: val_accuracy did not improve from 0.84648\n","1133/1133 [==============================] - 910s 803ms/step - loss: 0.1156 - accuracy: 0.9603 - val_loss: 0.6065 - val_accuracy: 0.8391\n","Epoch 6/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9688\n","Epoch 00006: val_accuracy did not improve from 0.84648\n","1133/1133 [==============================] - 911s 804ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.6515 - val_accuracy: 0.8437\n","Epoch 7/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9721\n","Epoch 00007: val_accuracy did not improve from 0.84648\n","1133/1133 [==============================] - 912s 805ms/step - loss: 0.0830 - accuracy: 0.9721 - val_loss: 0.7236 - val_accuracy: 0.8454\n","Epoch 8/50\n","1133/1133 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9762\n","Epoch 00008: val_accuracy improved from 0.84648 to 0.84824, saving model to gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5\n","1133/1133 [==============================] - 915s 807ms/step - loss: 0.0718 - accuracy: 0.9762 - val_loss: 0.7368 - val_accuracy: 0.8482\n"]}],"source":["model.load_weights('gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_4.h5')\n","base_model.trainable = True\n","model.summary()\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","#model.load_weights('gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5')\n","\n","history = model.fit(\n","                    train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=validation_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    class_weight = ClassWeights,\n","                    epochs=50,\n","                    callbacks=[early,mc, log]\n","                    )\n","\n"]},{"cell_type":"code","source":["model.load_weights('gdrive/MyDrive/final_project/weights/resnetV2_600_unlabel_mod_4.h5')"],"metadata":{"id":"9hVtXjreRG4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9P6nHhlYk3L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641266044836,"user_tz":-480,"elapsed":3261,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"8f953506-2040-444e-fb9d-8b3b148146e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2800 validated image filenames.\n"]}],"source":["# testing data extract features\n","test_files = pd.read_csv('/content/gdrive/MyDrive/final_project/sample_output.csv')\n","test_files['Type'] = test_files['Type'].astype('str')\n","test_dir='gdrive/MyDrive/final_project/test/test'\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","testing_generator = test_datagen.flow_from_dataframe(\n","    dataframe = test_files,\n","    directory = test_dir,\n","    target_size = (600, 600),\n","    x_col = 'Name',\n","    y_col = 'Type',\n","    batch_size = 10,\n","    class_mode = None,\n","    shuffle = False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjs2Hqf_ZBue"},"outputs":[],"source":["pred = model.predict(testing_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jp57VVT-byZt","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1641267591161,"user_tz":-480,"elapsed":26,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"2bc7a4ef-7d7a-4f8f-89cc-da8644e2833e"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1b7ee749-7591-4017-8cd1-8396c0dac7e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2795</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2796</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2797</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2798</th>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2799</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2800 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b7ee749-7591-4017-8cd1-8396c0dac7e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1b7ee749-7591-4017-8cd1-8396c0dac7e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1b7ee749-7591-4017-8cd1-8396c0dac7e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      0\n","0     3\n","1     2\n","2     0\n","3     0\n","4     0\n","...  ..\n","2795  3\n","2796  1\n","2797  3\n","2798  3\n","2799  0\n","\n","[2800 rows x 1 columns]"]},"metadata":{},"execution_count":14}],"source":["pred = np.argmax(pred, axis=1)\n","pd.DataFrame(pred)"]},{"cell_type":"markdown","metadata":{"id":"g4QdSK4mC3h8"},"source":["## export output csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHgwOAjfC6B6","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1641267591162,"user_tz":-480,"elapsed":22,"user":{"displayName":"陳大黑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05035539324213646874"}},"outputId":"96180532-026b-4b60-9643-f903398615ed"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a99dceae-23ba-4706-acf0-2482d9ef5f77\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000d70d25191ad64f00ca88a227c5985.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0030def9579a3cb2f5d334dee7a1fb78.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00323f13dd4c931d2b98382318fff36f.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0047247f1be33a5a0cee4470760dcdf7.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>006ef2a336bd15f53b50440837a847b2.jpg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2795</th>\n","      <td>ffa9fa81f310f5127c638b614a5a6034.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2796</th>\n","      <td>ffc3fa52be8106b071dbb4d45dab5041.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2797</th>\n","      <td>ffdc0dbd42650ace9a1be2c0d11bfa73.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2798</th>\n","      <td>ffed19041a89c1e6d9551d43d4584bc1.jpg</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2799</th>\n","      <td>fffcb9f1a43b0c841a4fc5614cd0844f.jpg</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2800 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a99dceae-23ba-4706-acf0-2482d9ef5f77')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a99dceae-23ba-4706-acf0-2482d9ef5f77 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a99dceae-23ba-4706-acf0-2482d9ef5f77');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                      Name  Type\n","0     000d70d25191ad64f00ca88a227c5985.jpg     3\n","1     0030def9579a3cb2f5d334dee7a1fb78.jpg     2\n","2     00323f13dd4c931d2b98382318fff36f.jpg     0\n","3     0047247f1be33a5a0cee4470760dcdf7.jpg     0\n","4     006ef2a336bd15f53b50440837a847b2.jpg     0\n","...                                    ...   ...\n","2795  ffa9fa81f310f5127c638b614a5a6034.jpg     3\n","2796  ffc3fa52be8106b071dbb4d45dab5041.jpg     1\n","2797  ffdc0dbd42650ace9a1be2c0d11bfa73.jpg     3\n","2798  ffed19041a89c1e6d9551d43d4584bc1.jpg     3\n","2799  fffcb9f1a43b0c841a4fc5614cd0844f.jpg     0\n","\n","[2800 rows x 2 columns]"]},"metadata":{},"execution_count":15}],"source":["output=pd.read_csv(\"gdrive/MyDrive/final_project/sample_output.csv\")\n","#將結果放到正確格式的csv\n","output[\"Type\"]=pd.DataFrame(pred)\n","output.to_csv('gdrive/MyDrive/final_project/output/600_psuedo_iter_4.csv',index=False)\n","output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWQmwacPBOUG"},"outputs":[],"source":["# model.save('gdrive/MyDrive/final_project/weights/resnetV2_384_class.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhWMHqv5B4QX"},"outputs":[],"source":["# model_load = models.load_model('gdrive/MyDrive/resnetV2_384.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1639839338094,"user":{"displayName":"NTUCESA臺大土木系學會","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgBGCMxAMw76Bx4UYnxZ_0AOYpGk56o2uUDY2I=s64","userId":"04886694692683773452"},"user_tz":-480},"id":"fDFQ1cxpCmr3","outputId":"d2747811-985d-48b2-e126-471a6fa04404"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_resnet_v2 (Functi  (None, 10, 10, 1536)     54336736  \n"," onal)                                                           \n","                                                                 \n"," batch_normalization_203 (Ba  (None, 10, 10, 1536)     10752     \n"," tchNormalization)                                               \n","                                                                 \n"," global_average_pooling2d (G  (None, 1536)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 128)               196736    \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               33024     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 4)                 1028      \n","                                                                 \n","=================================================================\n","Total params: 54,578,276\n","Trainable params: 233,860\n","Non-trainable params: 54,344,416\n","_________________________________________________________________\n"]}],"source":["# model_load.summary()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"resnetV2_600_unlabel_train.ipynb","provenance":[{"file_id":"18AR1op2HknRteldqzgfZAtia4ZevdTlm","timestamp":1640606478940},{"file_id":"18hbjLRezqulEybje-VBZ29FmE7wDhcBk","timestamp":1640377101142},{"file_id":"1fq1YAgqiojBc-ZcTIVFMrwDgXflLzf3Y","timestamp":1640250625709},{"file_id":"1d9miY5HKkhsOKQ0gjS3X8KNnRWZRwqDO","timestamp":1640090751611},{"file_id":"15szB04sC5k5hMr6ioisC27VOvyTxLvZW","timestamp":1640090430363},{"file_id":"1fCN-X_AtJC6c_v2dfBU5N2Gi1i9i5MOW","timestamp":1639894733257},{"file_id":"1vgXBfsQfe9Y9NOE8Aeu6nM4h3EPOmxDF","timestamp":1639772438198},{"file_id":"1o0-R71jSopqJv1c8x-SpVjL5SbmW3K7g","timestamp":1639754473180},{"file_id":"1z2AHYhWXTisCYZ2gfHgQiGkysJ5aBtzF","timestamp":1639744378310}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}